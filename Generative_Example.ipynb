{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating/initializing random topics and words\n",
    "\n",
    "- Collection of basic blogs at bottom https://devo-evo.lab.asu.edu/methods/?q=node/42\n",
    "- The original Edwin Chen github repo on Sarah Palin: https://github.com/echen/sarah-palin-lda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "documents.append(\"I like eating broccoli, and munching on avocados. \"+ \\\n",
    "                \"I would drink lots of Gatorade, diet Coke, Ginger ale, \" + \\\n",
    "                \"and devour cake. Cheesecake is delicious.\")\n",
    "documents.append(\"Puppies and kittens are adorable. Hamsters are cute. Koalas \" + \\\n",
    "                \"are so furry. My pet chihuahua and your pet Spaniel play with \" + \\\n",
    "                \"the Golden Retriever.\")\n",
    "documents.append(\"Puppies and kittens are adorable. Hamsters are cute. Koalas \" + \\\n",
    "                \"are so furry. My pet chihuahua and your pet Spaniel play with \" + \\\n",
    "                \"the Golden Retriever.\")\n",
    "documents.append(\"Puppies and kittens are adorable. Hamsters are cute. Koalas \" + \\\n",
    "                \"are so furry. My pet chihuahua and your pet Spaniel play with \" + \\\n",
    "                \"the Golden Retriever.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of words in the above categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Get the vocabulary using regular expressions\n",
    "def docs2vocab( documents ):\n",
    "    \n",
    "    alldocs = \"\"\n",
    "    for doc in documents:\n",
    "        alldocs += doc\n",
    "    vocabulary = re.split('; |, | |\\.', alldocs)\n",
    "    vocabulary = filter( lambda(elt): elt!='', list(set(vocabulary)))\n",
    "    \n",
    "    return vocabulary\n",
    "\n",
    "# For a single document, translate it into it's vocabulary integers\n",
    "def doc2vocab( doc, vocab ):\n",
    "    \n",
    "    word2vocab = dict( zip( vocab, range(len(vocab))))\n",
    "    doc_words = re.split('; |, | |\\.', doc)\n",
    "    translated_words = [ word2vocab[word] for word in doc_words if word in word2vocab.keys() ]\n",
    "    \n",
    "    return translated_words\n",
    "\n",
    "# Take integer words, and translate them back to a list of ascii words\n",
    "def vocab2doc( translated, vocab ):\n",
    "    return [ vocabulary[ int_word ] for int_word in translated ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of how to use the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a vocabulary from documents\n",
    "vocabulary = docs2vocab( documents )\n",
    "\n",
    "# Integer words, ascii words, and both words in list format\n",
    "document = documents[0]\n",
    "int_words = doc2vocab(document, vocabulary)\n",
    "ascii_words = vocab2doc( int_words, vocabulary )\n",
    "int_ascii = zip( int_words, ascii_words )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some random assignments\n",
    "\n",
    "Topic distribution is $\\theta \\sim Dir( \\alpha )$, so we'd like $P(\\theta|\\alpha)$. These are sampled once per document; therefore, there are $M$ of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = [5,5]\n",
    "theta = np.random.dirichlet( alphas )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a topic distribution as specified by $P(\\theta|\\alpha)$, we'd like to take $N$ samples  from the distribution specified by $\\theta$, each of which is called $z_n$. So,\n",
    "\n",
    "$z_n \\sim Multi( \\theta )$\n",
    "\n",
    "Formally, this is $P(z_n | \\theta) = \\frac{N!}{1!2!\\cdots k!} \\theta_1^{z_n^{(1)}} \\theta_2^{z_n^{(2)}} \\cdots \\theta_k^{z_n^{(k)}}$ is a multinomial distribution, with parameter $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "z_n = np.random.multinomial( 1, thetas, size=N )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the topic $z_n$ and an overall word distribution as specified by $\\beta$, the word distribution is a multinomial distribution with parameter $\\beta$. Here, the parameter $\\beta$ is a matrix of size $k \\times V$, since $z_n \\in [1, k]$, i.e. $k$ topics, and there are $V$ words.\n",
    "\n",
    "The probability $P( w | z_n, \\beta )$ is a proper distribution whose columns and rows both sum to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_t_n = np.random.multinomial( V, betas, size=N )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the given topic distribution $\\theta = [\\theta_1, \\theta_2, \\theta_3, \\cdots, \\theta_M$], the probability of that the $n^{th}$ word is from topic $k$ is $P( z_n = k | \\theta )$, which is simply $\\theta_k$. That is to say, the probability that $z_n^{(k)} = 1$, or $P(z_n^{(k)}=1 | \\theta, \\alpha)$ is simply the parameter $\\theta_k$. \n",
    "\n",
    "Then, we can write $P( z_n, \\theta | \\alpha ) = P( z_n | \\alpha) P(\\theta | \\alpha)$. If we are looking over $N$ words and each of them the draws are independent, then we have $P( \\theta, z | \\alpha ) = \\prod_n P( z_n | \\alpha ) P(\\theta | \\alpha ) = P(\\theta | \\alpha) \\prod_n P( z_n | \\theta )$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.19999999999999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
